{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306ae867",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolov3_tf2.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myolov3_tf2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YoloV3\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myolov3_tf2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transform_images\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myolov3_tf2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_boxes\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yolov3_tf2.models'"
     ]
    }
   ],
   "source": [
    "from absl import flags\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "sys.argv = sys.argv[:1]\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS(sys.argv)\n",
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from yolov3_tf2.models import YoloV3\n",
    "from yolov3_tf2.dataset import transform_images\n",
    "from yolov3_tf2.utils import convert_boxes\n",
    "\n",
    "from deep_sort import preprocessing\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from tools import generate_detections as gdet\n",
    "\n",
    "class_names = [c.strip() for c in open(\"C:\\\\Users\\\\User\\\\Desktop\\\\Computer-Vision-using-Python\\\\Deep Simple Online Realtime Tracking (Deep SORT)\\\\data\\\\labels\\\\coco.names\").readlines()]\n",
    "yolo = YoloV3(classes=len(class_names))\n",
    "yolo.load_weights(\"C:\\\\Users\\\\User\\\\Desktop\\\\Computer-Vision-using-Python\\Deep Simple Online Realtime Tracking (Deep SORT)\\\\weights\\\\yolov3.weights\")\n",
    "\n",
    "max_cosine_distance = 0.5\n",
    "nn_budget = None\n",
    "nms_max_overlap = 0.8\n",
    "\n",
    "model_filename = 'model_data/mars-small128.pb'\n",
    "encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "metric = nn_matching.NearestNeighborDistanceMetric('cosine', max_cosine_distance, nn_budget)\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "vid = cv2.VideoCapture('traffic.mp4')\n",
    "\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "vid_fps =int(vid.get(cv2.CAP_PROP_FPS))\n",
    "vid_width,vid_height = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)), int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter('results.avi', codec, vid_fps, (vid_width, vid_height))\n",
    "\n",
    "from _collections import deque\n",
    "pts = [deque(maxlen=30) for _ in range(1000)]\n",
    "\n",
    "counter = []\n",
    "cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
    "while True:\n",
    "    _, img = vid.read()\n",
    "    if img is None:\n",
    "        print('Completed')\n",
    "        break\n",
    "\n",
    "    img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_in = tf.expand_dims(img_in, 0)\n",
    "    img_in = transform_images(img_in, 416)\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    boxes, scores, classes, nums = yolo.predict(img_in)\n",
    "\n",
    "    classes = classes[0]\n",
    "    names = []\n",
    "    for i in range(len(classes)):\n",
    "        names.append(class_names[int(classes[i])])\n",
    "    names = np.array(names)\n",
    "    converted_boxes = convert_boxes(img, boxes[0])\n",
    "    features = encoder(img, converted_boxes)\n",
    "\n",
    "    detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in\n",
    "                  zip(converted_boxes, scores[0], names, features)]\n",
    "\n",
    "    boxs = np.array([d.tlwh for d in detections])\n",
    "    scores = np.array([d.confidence for d in detections])\n",
    "    classes = np.array([d.class_name for d in detections])\n",
    "    indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
    "    detections = [detections[i] for i in indices]\n",
    "\n",
    "    tracker.predict()\n",
    "    tracker.update(detections)\n",
    "\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i)[:3] for i in np.linspace(0,1,20)]\n",
    "\n",
    "    current_count = int(0)\n",
    "\n",
    "    for track in tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update >1:\n",
    "            continue\n",
    "        bbox = track.to_tlbr()\n",
    "        class_name= track.get_class()\n",
    "        color = colors[int(track.track_id) % len(colors)]\n",
    "        color = [i * 255 for i in color]\n",
    "\n",
    "        cv2.rectangle(img, (int(bbox[0]),int(bbox[1])), (int(bbox[2]),int(bbox[3])), color, 2)\n",
    "        cv2.rectangle(img, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)\n",
    "                    +len(str(track.track_id)))*10, int(bbox[1])), color, -1)\n",
    "        cv2.putText(img, class_name+\"-\"+str(track.track_id), (int(bbox[0]), int(bbox[1]-10)), 0, 0.5,\n",
    "                    (255, 255, 255),2)\n",
    "\n",
    "        center = (int(((bbox[0]) + (bbox[2]))/2), int(((bbox[1])+(bbox[3]))/2))\n",
    "        pts[track.track_id].append(center)\n",
    "\n",
    "        for j in range(1, len(pts[track.track_id])):\n",
    "            if pts[track.track_id][j-1] is None or pts[track.track_id][j] is None:\n",
    "                continue\n",
    "            thickness = int(np.sqrt(64/float(j+1))*2)\n",
    "           \n",
    "            cv2.line(img, (pts[track.track_id][j-1]), (pts[track.track_id][j]), color, thickness)\n",
    "\n",
    "        height, width, _ = img.shape\n",
    "        #cv2.line(img, (0, int(3*height/6+height/20)), (width, int(3*height/6+height/20)), (0, 255, 0), thickness=2)\n",
    "        #cv2.line(img, (0, int(3*height/6-height/20)), (width, int(3*height/6-height/20)), (0, 255, 0), thickness=2)\n",
    "\n",
    "        center_y = int(((bbox[1])+(bbox[3]))/2)\n",
    "\n",
    "        if center_y <= int(3*height/6+height/20) and center_y >= int(3*height/6-height/20):\n",
    "            if class_name == 'car' or class_name == 'truck':\n",
    "                counter.append(int(track.track_id))\n",
    "                current_count += 1\n",
    "\n",
    "    #total_count = len(set(counter))\n",
    "    #cv2.putText(img, \"Current Vehicle Count: \" + str(current_count), (0, 80), 0, 1, (0, 0, 255), 2)\n",
    "    #cv2.putText(img, \"Total Vehicle Count: \" + str(total_count), (0,130), 0, 1, (0,0,255), 2)\n",
    "\n",
    "    fps = 1./(time.time()-t1)\n",
    "    cv2.putText(img, \"FPS: {:.2f}\".format(fps), (0,30), 0,0.5,(0,0,255),2) \n",
    "    cv2.resizeWindow('output', 1024, 768)\n",
    "    cv2.imshow('output', img)\n",
    "    out.write(img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53e852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
